{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model-Naive-Bayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8DsFCCkmLNvz"
      },
      "source": [
        "# NLP Supervised Learning Using Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Db_D8uwILuu8"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_PHmHQWsId89"
      },
      "source": [
        "# Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('../data/alfa_dataset.csv - Sheet1.csv', delimiter = ',')\n",
        "#print(dataset.head())\n",
        "#print(dataset.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0osUvZ2iJqlh"
      },
      "source": [
        "# Cleaning the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "corpus = []\n",
        "for i in range(0, 60):\n",
        "  #print(\"here\", dataset['Log file entries'][i])\n",
        "  log_entry = re.sub(r\"\\[[(\\w+\\d+\\s+:\\.)]+|\\]|/(\\w+/)+|(http(://(\\w+\\.)+))+|(https(://(\\w+\\.)+))+|(\\([\\w+\\.|\\w+,|\\w+\\)|\\w+\\\\|\\.]+)|line(\\s+\\d+)|referer(:\\w+)+|[^a-zA-Z\\s+]|\\d+|\\w+(\\-|_|\\w+)*\\.php|AH|referer|COS|za\", \" \", dataset['Log file entries'][i])\n",
        "  #print(log_entry)\n",
        "  log_entry = log_entry.split()\n",
        "  ps = PorterStemmer()\n",
        "  log_entry = [ps.stem(word) for word in log_entry]\n",
        "  #print(log_entry)\n",
        "  log_entry = ' '.join(log_entry)\n",
        "  #print(log_entry)\n",
        "  corpus.append(log_entry)\n",
        "\n",
        "#print(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-ga0D85a8E_r"
      },
      "source": [
        "# Creating the Bag of Words Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "countVectorizer = CountVectorizer(max_features = 1500)\n",
        "X = countVectorizer.fit_transform(corpus).toarray()\n",
        "y = dataset.iloc[ :, -1].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VlESs0lVoqYv"
      },
      "source": [
        "# Splitting the dataset into Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "46EFd8hJo4Uw"
      },
      "source": [
        "# Training Naive Bayes Model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "GaussianNB(priors=None, var_smoothing=1e-09)"
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb_classifier = GaussianNB()\n",
        "nb_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KHBwrgpvpM3h"
      },
      "source": [
        "# Predicting the test set results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = nb_classifier.predict(X_test)\n",
        "#print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "#print(cm)\n",
        "#accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "['naive-bayes-model.pkl']"
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the model\n",
        "from sklearn.externals import joblib\n",
        "joblib.dump(nb_classifier, 'naive-bayes-model.pkl')\n",
        "print(\"Model dumped!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the model you just saved\n",
        "nb_classifier = joblib.load('naive-bayes-model.pkl')"
      ]
    }
  ]
}